## Natural Language Processing with Probabilistic Models
You will learn:  
a) Create a simple auto-correct algorithm using minimum edit distance and dynamic programming,  
b) Apply the Viterbi Algorithm for part-of-speech (POS) tagging, which is important for computational linguistics,  
c) Write a better auto-complete algorithm using an N-gram language model, and   
d) Write your own Word2Vec model that uses a neural network to compute word embeddings using a continuous bag-of-words model.  
