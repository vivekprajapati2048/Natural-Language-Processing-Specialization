## Natural Language Processing with Sequence Models
You will learn:  
a) Train a neural network with GLoVe word embeddings to perform sentiment analysis of tweets,  
b) Generate synthetic Shakespeare text using a Gated Recurrent Unit (GRU) language model,  
c) Train a recurrent neural network to perform named entity recognition (NER) using LSTMs with linear layers, and   
d) Use so-called ‘Siamese’ LSTM models to compare questions in a corpus and identify those that are worded differently but have the same meaning. 
