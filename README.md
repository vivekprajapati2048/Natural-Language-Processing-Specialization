# Natural-Language-Processing-Specialization
This Specialization is made of 4 hands-on courses focusing on skills like Sentiment Analysis, Siamese Networks, Hidden Markov Model, Transformers, Attention Models, Machine Translation, Word Embeddings, Locality-Sensitive Hashing, Vector Space Models, Word2vec, Parts-of-Speech Tagging, N-gram Language Models.
1. [NLP with Classification and Vector Spaces](https://github.com/vivekprajapati2048/Natural-Language-Processing-Specialization/tree/master/1.%20Natural%20Language%20Processing%20with%20Classification%20and%20Vector%20Spaces)
2. [NLP with Probabilistic Models](https://github.com/vivekprajapati2048/Natural-Language-Processing-Specialization/tree/master/2.%20Natural%20Language%20Processing%20with%20Probabilistic%20Models)
3. NLP with Sequence Models
4. NLP with Attention Models  

This Specialization is designed and taught by two experts in NLP, machine learning, and deep learning. Younes Bensouda Mourri is an Instructor of AI at Stanford University who also helped build the Deep Learning Specialization. ≈Åukasz Kaiser is a Staff Research Scientist at Google Brain and the co-author of Tensorflow, the Tensor2Tensor and Trax libraries, and the Transformer paper.
